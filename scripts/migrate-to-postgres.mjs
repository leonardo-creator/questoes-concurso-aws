#!/usr/bin/env node
/**
 * Script de migra√ß√£o: JSON chunks ‚Üí PostgreSQL AWS RDS
 * 
 * Este script migra todas as quest√µes dos arquivos JSON para o banco PostgreSQL,
 * processando em lotes para evitar sobrecarga de mem√≥ria e timeout.
 */

import { PrismaClient } from '@prisma/client';
import fs from 'fs/promises';
import path from 'path';
import { fileURLToPath } from 'url';

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

const prisma = new PrismaClient();

// Configura√ß√µes
const BATCH_SIZE = 1000; // Processar 1000 quest√µes por vez
const CHUNKS_DIR = path.join(__dirname, '../chunks');
const LOG_INTERVAL = 5000; // Log a cada 5000 quest√µes

/**
 * Normaliza dados da quest√£o para o formato do banco
 */
function normalizeQuestion(questao) {
  return {
    questaoId: questao.id,
    dificuldade: questao.dificuldade || 1,
    bancasNome: questao.bancas_nome || '',
    bancasDescricao: questao.bancas_descricao || '',
    bancasSigla: questao.bancas_sigla || '',
    bancasOab: questao.bancas_oab || false,
    cargosDescricao: questao.cargos_descricao || '',
    orgaosNome: questao.orgaos_nome || '',
    orgaosSigla: questao.orgaos_sigla || '',
    orgaosUf: questao.orgaos_uf || '',
    anos: questao.anos || new Date().getFullYear(),
    tipo: questao.tipo || '',
    grupoQuestaoEnunciado: questao.grupoQuestao_enunciado || '',
    enunciado: questao.enunciado || '',
    hasImage: questao.hasImage === 'True',
    hasImageItens: questao.hasImageItens === 'True',
    provasNivel: questao.provas_nivel || '',
    areasDescricao: questao.areas_descricao,
    itens: questao.itens || [],
    resposta: questao.resposta || '',
    assuntosPalavrasChave: questao.assuntos_palavrasChave || [],
    // üîß CORRE√á√ÉO: Usar null em vez de string vazia para campos √∫nicos
    codigoReal: questao.codigo_real && questao.codigo_real.trim() !== '' ? questao.codigo_real.trim() : null,
    disciplinaReal: questao.disciplina_real || '',
    assuntoReal: questao.assunto_real || '',
    anulada: questao.anulada === 'True',
    desatualizada: questao.desatualizada === 'True'
  };
}

/**
 * Remove duplicatas dentro do lote baseado em questaoId
 */
function removeDuplicatesFromBatch(questions) {
  const seen = new Set();
  const unique = [];
  
  for (const question of questions) {
    const id = question.id;
    if (!seen.has(id)) {
      seen.add(id);
      unique.push(question);
    }
  }
  
  if (unique.length < questions.length) {
    console.log(`üîç Removidas ${questions.length - unique.length} duplicatas dentro do lote`);
  }
  
  return unique;
}

/**
 * Verifica quais quest√µes j√° existem no banco
 */
async function getExistingQuestions(questaoIds) {
  const existing = await prisma.question.findMany({
    where: {
      questaoId: {
        in: questaoIds
      }
    },
    select: { questaoId: true }
  });
  
  return new Set(existing.map(q => q.questaoId));
}

/**
 * Processa um lote de quest√µes com verifica√ß√£o de duplicatas
 */
async function processBatch(questions, batchNumber, chunkFile) {
  try {
    // 1. Remover duplicatas dentro do pr√≥prio lote
    const uniqueQuestions = removeDuplicatesFromBatch(questions);
    
    // 2. Normalizar as quest√µes
    const normalizedQuestions = uniqueQuestions.map(normalizeQuestion);
    
    // 3. Verificar quais j√° existem no banco
    const questaoIds = normalizedQuestions.map(q => q.questaoId);
    const existingIds = await getExistingQuestions(questaoIds);
    
    // 4. Filtrar apenas quest√µes novas
    const newQuestions = normalizedQuestions.filter(q => !existingIds.has(q.questaoId));
    
    let inserted = 0;
    let skipped = questions.length - newQuestions.length;
    
    if (newQuestions.length === 0) {
      console.log(`‚è≠Ô∏è  ${chunkFile} - Lote ${batchNumber}: Todas as ${questions.length} quest√µes j√° existem`);
      return { inserted: 0, skipped };
    }
    
    // 5. Tentar inser√ß√£o em lote primeiro
    try {
      await prisma.question.createMany({
        data: newQuestions,
        skipDuplicates: true
      });
      inserted = newQuestions.length;
      console.log(`‚úÖ ${chunkFile} - Lote ${batchNumber}: ${inserted} inseridas, ${skipped} j√° existiam`);
    } catch (batchError) {
      console.warn(`‚ö†Ô∏è  Erro na inser√ß√£o em lote: ${batchError.message}`);
      console.log(`üîÑ Tentando inser√ß√£o individual...`);
      
      // 6. Se falhar, inserir uma por vez
      for (const question of newQuestions) {
        try {
          await prisma.question.upsert({
            where: { questaoId: question.questaoId },
            update: {}, // N√£o atualizar se j√° existir
            create: question
          });
          inserted++;
        } catch (singleError) {
          console.warn(`‚ö†Ô∏è  Quest√£o ${question.questaoId} ignorada: ${singleError.message}`);
          skipped++;
        }
      }
      
      console.log(`üîÑ ${chunkFile} - Lote ${batchNumber}: ${inserted} inseridas individualmente, ${skipped} problemas`);
    }
    
    return { inserted, skipped };
    
  } catch (error) {
    console.error(`‚ùå Erro grave no lote ${batchNumber}:`, error.message);
    return { inserted: 0, skipped: questions.length };
  }
}

/**
 * Migra todas as quest√µes de um arquivo chunk
 */
async function migrateChunk(chunkFile, chunkIndex, totalChunks) {
  console.log(`üìÇ [${chunkIndex}/${totalChunks}] Processando: ${chunkFile}`);
  
  try {
    const filePath = path.join(CHUNKS_DIR, chunkFile);
    const content = await fs.readFile(filePath, 'utf8');
    const questions = JSON.parse(content);
    
    if (!Array.isArray(questions)) {
      console.warn(`‚ö†Ô∏è  ${chunkFile} n√£o cont√©m array v√°lido`);
      return { inserted: 0, skipped: 0 };
    }
    
    console.log(`üìä ${chunkFile}: ${questions.length} quest√µes encontradas`);
    
    let totalInserted = 0;
    let totalSkipped = 0;
    
    // Processar em lotes
    for (let i = 0; i < questions.length; i += BATCH_SIZE) {
      const batch = questions.slice(i, i + BATCH_SIZE);
      const batchNumber = Math.floor(i / BATCH_SIZE) + 1;
      const totalBatches = Math.ceil(questions.length / BATCH_SIZE);
      
      console.log(`üîÑ ${chunkFile}: Processando lote ${batchNumber}/${totalBatches} (${batch.length} quest√µes)`);
      
      const result = await processBatch(batch, batchNumber, chunkFile);
      totalInserted += result.inserted;
      totalSkipped += result.skipped;
      
      // Pequena pausa para n√£o sobrecarregar o banco
      await new Promise(resolve => setTimeout(resolve, 200));
    }
    
    console.log(`‚úÖ ${chunkFile}: ${totalInserted} inseridas, ${totalSkipped} j√° existiam/problemas\n`);
    return { inserted: totalInserted, skipped: totalSkipped };
    
  } catch (error) {
    console.error(`‚ùå Erro ao processar ${chunkFile}:`, error.message);
    return { inserted: 0, skipped: 0 };
  }
}

/**
 * Remove duplicatas do banco baseado em questaoId
 */
async function cleanDuplicates() {
  console.log('üßπ Verificando e removendo duplicatas...');
  
  try {
    // Encontrar duplicatas
    const duplicates = await prisma.$queryRaw`
      SELECT "questaoId", COUNT(*) as count 
      FROM questions 
      GROUP BY "questaoId" 
      HAVING COUNT(*) > 1
      ORDER BY count DESC
    `;
    
    if (duplicates.length === 0) {
      console.log('‚úÖ Nenhuma duplicata encontrada');
      return 0;
    }
    
    console.log(`üìä Encontradas ${duplicates.length} quest√µes com duplicatas`);
    
    let totalRemoved = 0;
    
    for (const duplicate of duplicates) {
      const questaoId = Number(duplicate.questaoId);
      
      // Buscar todos os registros duplicados ordenados por data de cria√ß√£o
      const records = await prisma.question.findMany({
        where: { questaoId },
        orderBy: { createdAt: 'desc' } // Manter o mais recente
      });
      
      // Remover todos exceto o primeiro (mais recente)
      const toDelete = records.slice(1);
      
      for (const record of toDelete) {
        await prisma.question.delete({
          where: { id: record.id }
        });
        totalRemoved++;
      }
      
      console.log(`üóëÔ∏è  questaoId ${questaoId}: removidas ${toDelete.length} duplicatas`);
    }
    
    console.log(`‚úÖ Total de registros duplicados removidos: ${totalRemoved}\n`);
    return totalRemoved;
    
  } catch (error) {
    console.error('‚ùå Erro ao limpar duplicatas:', error.message);
    return 0;
  }
}

/**
 * Atualiza estat√≠sticas do banco
 */
async function updateStats() {
  console.log('üìà Atualizando estat√≠sticas...');
  
  const [
    totalQuestoes,
    bancas,
    anos,
    orgaos
  ] = await Promise.all([
    prisma.question.count(),
    prisma.question.groupBy({
      by: ['bancasSigla'],
      _count: { bancasSigla: true }
    }),
    prisma.question.groupBy({
      by: ['anos'],
      _count: { anos: true }
    }),
    prisma.question.groupBy({
      by: ['orgaosNome'],
      _count: { orgaosNome: true }
    })
  ]);
  
  await prisma.questionStats.upsert({
    where: { id: 'main' },
    update: {
      totalQuestoes,
      totalBancas: bancas.length,
      totalAnos: anos.length,
      totalOrgaos: orgaos.length,
      atualizadoEm: new Date()
    },
    create: {
      id: 'main',
      totalQuestoes,
      totalBancas: bancas.length,
      totalAnos: anos.length,
      totalOrgaos: orgaos.length
    }
  });
  
  console.log(`üìä Estat√≠sticas atualizadas:
    - Total de quest√µes: ${totalQuestoes.toLocaleString()}
    - Bancas: ${bancas.length}
    - Anos: ${anos.length}
    - √ìrg√£os: ${orgaos.length}`);
}

/**
 * Fun√ß√£o principal de migra√ß√£o
 */
async function main() {
  console.log('üöÄ Iniciando migra√ß√£o JSON ‚Üí PostgreSQL AWS RDS');
  console.log('=' .repeat(60));
  
  const startTime = Date.now();
  const shouldClean = process.argv.includes('--clean');
  
  try {
    // Verificar conex√£o com banco
    await prisma.$connect();
    console.log('‚úÖ Conectado ao PostgreSQL AWS RDS\n');
    
    // Verificar estado atual do banco
    const existingCount = await prisma.question.count();
    console.log(`üìä Estado atual: ${existingCount.toLocaleString()} quest√µes no banco`);
    
    // Limpar duplicatas se solicitado
    if (shouldClean) {
      console.log('üßπ Flag --clean detectada. Limpando duplicatas...');
      await cleanDuplicates();
      
      const newCount = await prisma.question.count();
      console.log(`üìä Ap√≥s limpeza: ${newCount.toLocaleString()} quest√µes no banco\n`);
    } else if (existingCount > 0) {
      console.log('‚ÑπÔ∏è  Use --clean para remover duplicatas antes da migra√ß√£o\n');
    }
    
    // Listar arquivos de chunks
    const files = await fs.readdir(CHUNKS_DIR);
    const chunkFiles = files
      .filter(file => file.startsWith('batch_') && file.endsWith('.json'))
      .sort((a, b) => {
        const numA = parseInt(a.match(/batch_(\d+)/)?.[1] || '0');
        const numB = parseInt(b.match(/batch_(\d+)/)?.[1] || '0');
        return numA - numB;
      });
    
    console.log(`üìÅ Encontrados ${chunkFiles.length} arquivos chunk para processar`);
    
    if (chunkFiles.length === 0) {
      console.log('‚ùå Nenhum arquivo chunk encontrado em ./chunks/');
      console.log('üìÅ Verifique se os arquivos est√£o no formato batch_XXX.json');
      return;
    }
    
    // Verificar alguns arquivos como exemplo
    console.log('üìã Primeiros arquivos a serem processados:');
    chunkFiles.slice(0, 5).forEach((file, index) => {
      console.log(`   ${index + 1}. ${file}`);
    });
    if (chunkFiles.length > 5) {
      console.log(`   ... e mais ${chunkFiles.length - 5} arquivos`);
    }
    console.log('');
    
    // Processar cada chunk
    let totalInserted = 0;
    let totalSkipped = 0;
    let processedFiles = 0;
    let failedFiles = 0;
    
    for (let i = 0; i < chunkFiles.length; i++) {
      const chunkFile = chunkFiles[i];
      console.log(`üîÑ Progresso geral: ${i + 1}/${chunkFiles.length} arquivos`);
      
      const result = await migrateChunk(chunkFile, i + 1, chunkFiles.length);
      
      if (result.inserted > 0 || result.skipped > 0) {
        processedFiles++;
        totalInserted += result.inserted;
        totalSkipped += result.skipped;
      } else {
        failedFiles++;
      }
      
      // Log de progresso a cada 10 arquivos ou quando atingir marcos
      if ((i + 1) % 10 === 0 || totalInserted % LOG_INTERVAL === 0) {
        const elapsed = ((Date.now() - startTime) / 1000).toFixed(1);
        const rate = totalInserted > 0 ? (totalInserted / parseFloat(elapsed)).toFixed(1) : '0';
        console.log(`üìà Progresso intermedi√°rio: ${totalInserted.toLocaleString()} quest√µes inseridas em ${elapsed}s (${rate} q/s)\n`);
      }
    }
    
    // Atualizar estat√≠sticas
    await updateStats();
    
    const totalTime = ((Date.now() - startTime) / 1000).toFixed(1);
    const avgRate = totalInserted > 0 ? (totalInserted / parseFloat(totalTime)).toFixed(1) : '0';
    
    console.log('\n' + '=' .repeat(60));
    console.log('üéâ Migra√ß√£o conclu√≠da!');
    console.log(`üìä Resultados finais:
    - Arquivos processados: ${processedFiles}/${chunkFiles.length} (${failedFiles} falharam)
    - Quest√µes novas inseridas: ${totalInserted.toLocaleString()}
    - Quest√µes j√° existiam/problemas: ${totalSkipped.toLocaleString()}
    - Total processado: ${(totalInserted + totalSkipped).toLocaleString()}
    - Tempo total: ${totalTime}s
    - Taxa m√©dia: ${avgRate} quest√µes/segundo`);
    
    if (failedFiles > 0) {
      console.log(`\n‚ö†Ô∏è  Aten√ß√£o: ${failedFiles} arquivos falharam no processamento`);
    }
    
  } catch (error) {
    console.error('‚ùå Erro durante a migra√ß√£o:', error);
    process.exit(1);
  } finally {
    await prisma.$disconnect();
  }
}

// Executar se chamado diretamente
if (process.argv[1] === fileURLToPath(import.meta.url)) {
  main().catch(console.error);
}

export { main as migrateToPostgres };
